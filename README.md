# ðŸš€ Lightweight Edgeâ€‘AI System for Realâ€‘Time Wafer & Die Defect Classification

> **Edgeâ€‘aware. Fabâ€‘realistic. Deploymentâ€‘ready.**

This repository contains a **Phaseâ€‘1 prototype** of an **Edgeâ€‘AI defect classification system** designed for **realâ€‘time semiconductor wafer and die inspection**. The solution uses a **lightweight CNN**, optimized for **CPUâ€‘only edge deployment** on **NXP i.MX RT devices** via the **NXP eIQ framework**.

The objective is **not leaderboard accuracy** â€” itâ€™s **technical credibility**: dataset realism, model feasibility, and edgeâ€‘deployment readiness.

---

## ðŸ“Œ Problem Context

Modern semiconductor fabs generate **massive volumes of inspection images** (optical + SEM). Centralized pipelines struggle with:

* ðŸš« High inference latency
* ðŸš« Bandwidth overhead from image transfer
* ðŸš« Poor scalability for realâ€‘time production lines

**Edgeâ€‘based defect classification** enables **early screening directly at the inspection tool**, reducing **data movement**, **latency**, and **operational cost**.

This repo proves that concept â€” clean, simple, and edgeâ€‘aware.

---

## ðŸŽ¯ Task Definition

* **Task Type:** Image Classification
* **Input:** Single grayscale wafer / die inspection image
* **Output:** One defect class label per image

ðŸ“Œ *Scope note:* This project focuses **strictly on classification** â€” **no detection or segmentation** in Phaseâ€‘1.

---

## ## ðŸ§ª Defect Classes

The model classifies inspection images into **8 non-overlapping, fab-realistic defect categories**, chosen to be visually distinguishable and representative of common wafer and die-level failure modes.

**Final Class Set (Phase-1):**
1. `clean`
2. `other`
3. `shorts`
4. `opens`
5. `bridges`
6. `cmp_scratches`
7. `cracks`
8. `malformed_vias`

This class design balances **realistic semiconductor inspection scenarios** with **Phase-1 feasibility** and is intentionally scoped to scale in Phase-2.

<img width="1065" height="602" alt="image" src="https://github.com/user-attachments/assets/3653974b-8f62-4d25-bcc4-18841774508e" />

<img width="983" height="558" alt="image" src="https://github.com/user-attachments/assets/0d19d852-e414-40b6-a352-f2a9f5c57a3c" />

---

## ðŸ“‚ Dataset

* **Minimum size:** 500+ images
* **Target size:** ~800 images
* **Class balance:** No class < 10%

### Data Sources

* WMâ€‘811K Wafer Defect Dataset
* SEM defect image datasets
* Curated academic inspection imagery

### Preprocessing

All images are:

* Converted to **grayscale**
* Resized to a **fixed resolution**
* Manually curated to contain **one dominant defect per image**

ðŸ“„ See **`DATASET.md`** for full provenance and curation details.

---

## ðŸ§  Model

* **Architecture:** Lightweight CNN

  * MobileNetV2 *or* EfficientNetâ€‘Lite
* **Training Framework:** PyTorch
* **Export Format:** ONNX

### ðŸŽ¯ Edge Constraints (Target)

| Constraint | Target                     |
| ---------- | -------------------------- |
| Model size | < 10 MB                    |
| Latency    | < 50 ms / image (CPU est.) |
| Deployment | NXP i.MX RT (CPUâ€‘only)     |

The ONNX model is compatible with **NXP eIQ** for downstream deployment.

---

## ðŸ—‚ Repository Structure

```
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ models/
â”œâ”€â”€ scripts/
â”œâ”€â”€ train.py
â”œâ”€â”€ eval.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ export_onnx.py
â”œâ”€â”€ DATASET.md
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

Clean layout. No chaos. Easy handoff.

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Train the Model

```bash
python train.py
```

### 3ï¸âƒ£ Evaluate the Model

```bash
python eval.py
```

### 4ï¸âƒ£ Run Inference on a Sample Image

```bash
python inference.py --image path/to/image.png
```

### 5ï¸âƒ£ Export to ONNX

```bash
python export_onnx.py
```

---

## ðŸ“Š Results (Phaseâ€‘1)

Phaseâ€‘1 evaluation prioritizes **feasibility and correctness**, not peak accuracy.

Reported metrics:

* Accuracy
* Macro Precision
* Macro Recall
* Confusion Matrix
* Model size

ðŸ“„ Detailed results are documented in the **Phaseâ€‘1 submission PDF**.

---

## âš ï¸ Limitations

Accepted (and intentional) Phaseâ€‘1 constraints:

* Limited dataset size vs. production fab data
* Latency is **estimated** (hardware benchmarking planned)
* Classification only (no localization)

This is a **proofâ€‘ofâ€‘feasibility**, not a final fab product.

---

## ðŸ›£ Phaseâ€‘2 Roadmap

* Deployment on **NXP i.MX RT hardware** using eIQ
* Onâ€‘device latency & memory benchmarking
* Incremental dataset expansion
* Optional defect localization extension

Translation: less theory, more silicon.

---

## ðŸ“Ž Disclaimer

Organizerâ€‘provided sample images are used **only for reference and visualization**. They are **not used** in training, validation, or testing.

---

## ðŸ–¼ï¸ Visual Reference Policy (Phase-1)

For the purpose of **documentation clarity only**, representative images shown in this file may include:

* Organizer-provided sample images, **or**
* **Synthetic / illustrative placeholder images** generated solely for visualization

These images are **not** used in:

* Training
* Validation
* Testing

All models are trained and evaluated **exclusively on real inspection images** sourced as documented in `DATASET.md`.

---


## ðŸ“š References

* WMâ€‘811K Wafer Map Defect Dataset
* SEM Defect Image Datasets
* Academic literature on semiconductor inspection & edge AI(ieee or springer)

---

ðŸ’¡ *Built to prove that edgeâ€‘first inspection AI is not just possible â€” itâ€™s practical.*
